{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cv.ipynb', 'submission.csv', 'test', 'test.ipynb', 'train']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(os.listdir(\"./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['broken_grain', 'full_grain', 'mixed_grain']\n",
    "def classNoGen(img):\n",
    "    if img[0] == 'b':\n",
    "        return 0\n",
    "    elif img[0] == 'f':\n",
    "        return 1\n",
    "    elif img[0] == 'm':\n",
    "        return 2\n",
    "    elif img[0] =='t':\n",
    "        return '-1'\n",
    "img_size = 150\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    path = data_dir\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = classNoGen(img)\n",
    "        img = cv2.imread(img_path)[...,::-1]\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        data.append([img, label])\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_data('./train')\n",
    "test= get_data('./train')\n",
    "p= get_data('./test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = []\n",
    "for i in train:\n",
    "    if(i[1] == 0):\n",
    "        l.append(\"broken_grain\")\n",
    "    elif(i[1] == 1):\n",
    "        l.append(\"full_grain\")\n",
    "    else:\n",
    "        l.append(\"mixed_grain\")\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "x_p =[]\n",
    "y_p = []\n",
    "\n",
    "for feature, label in train:\n",
    "  x_train.append(feature)\n",
    "  y_train.append(label)\n",
    "\n",
    "for feature, label in test:\n",
    "  x_test.append(feature)\n",
    "  y_test.append(label)\n",
    "\n",
    "for feature, label in p:\n",
    "  x_p.append(feature)\n",
    "  y_p.append(label)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_test = np.array(x_test) / 255\n",
    "x_p = np.array(x_p) / 255\n",
    "\n",
    "x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_p.reshape(-1, img_size, img_size, 1)\n",
    "y_p = np.array(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)\n",
    "datagen.fit(x_test)\n",
    "datagen.fit(x_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = model.predict(x_train)\n",
    "test_features = model.predict(x_test)\n",
    "p_features = model.predict(x_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4 512\n"
     ]
    }
   ],
   "source": [
    "n_train, x, y, z = train_features.shape\n",
    "n_test, x, y, z = test_features.shape\n",
    "n_p, x, y, z = p_features.shape\n",
    "numFeatures = x * y * z\n",
    "print(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.2747 - accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2241 - accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0116 - accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7903 - accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6942 - accuracy: 0.8333\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6697 - accuracy: 0.8333\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6082 - accuracy: 0.9167\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5132 - accuracy: 0.9167\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4251 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3615 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3297 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3057 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2739 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2341 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1966 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1698 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1531 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1416 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1306 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1179 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0910 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0800 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0712 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0646 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0597 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0558 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0520 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n",
    "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(train_features, y_train, batch_size=128, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1997)\n",
    "# Number of estimators\n",
    "n_estimators = 10\n",
    "# Proporition of samples to use to train each training\n",
    "max_samples = 0.8\n",
    "\n",
    "max_samples *= n_train\n",
    "max_samples = int(max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list()\n",
    "random = np.random.randint(50, 100, size = n_estimators)\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    \n",
    "    # Model\n",
    "    model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape = (x, y, z)),\n",
    "                                # One layer with random size\n",
    "                                    tf.keras.layers.Dense(random[i], activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "                                ])\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Store model\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.1351 - accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8764 - accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8509 - accuracy: 0.7778\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6943 - accuracy: 0.7778\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5505 - accuracy: 0.7778\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4091 - accuracy: 0.7778\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2867 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2311 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2175 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2033 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.9967 - accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2017 - accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9442 - accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6417 - accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5787 - accuracy: 0.8889\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5365 - accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4226 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3475 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3246 - accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3100 - accuracy: 0.7778\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 1.1010 - accuracy: 0.2222\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0857 - accuracy: 0.7778\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8621 - accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7778\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4621 - accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.8889\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2549 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2065 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2016 - accuracy: 0.8889\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.3969 - accuracy: 0.1111\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1880 - accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0414 - accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8375 - accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6795 - accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6181 - accuracy: 0.8889\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5267 - accuracy: 0.8889\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3032 - accuracy: 0.8889\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 1.3489 - accuracy: 0.2222\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2566 - accuracy: 0.5556\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8740 - accuracy: 0.7778\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7778\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2623 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2028 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2173 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2006 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1477 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0952 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 1.5009 - accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2456 - accuracy: 0.4444\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1309 - accuracy: 0.4444\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7985 - accuracy: 0.4444\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4851 - accuracy: 0.7778\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3808 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3826 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3573 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2810 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1984 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.1353 - accuracy: 0.4444\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1472 - accuracy: 0.5556\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8358 - accuracy: 0.4444\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4797 - accuracy: 0.7778\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4251 - accuracy: 0.7778\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.8889\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1913 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1383 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1290 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.2029 - accuracy: 0.4444\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6216 - accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4867 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6206 - accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5782 - accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3209 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1364 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0813 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0765 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 1.3076 - accuracy: 0.4444\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9731 - accuracy: 0.5556\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.5556\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3807 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8889\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3410 - accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2414 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1763 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1583 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1410 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 1.2783 - accuracy: 0.1111\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8714 - accuracy: 0.5556\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7376 - accuracy: 0.8889\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6852 - accuracy: 0.8889\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5601 - accuracy: 0.8889\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8889\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3160 - accuracy: 0.8889\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2319 - accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1780 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    # Train each model on a bag of the training data\n",
    "    train_idx = np.random.choice(len(train_features), size = max_samples)\n",
    "    histories.append(models[i].fit(train_features[train_idx], y_train[train_idx], batch_size=128, epochs=10, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(n_estimators):\n",
    "    predictions.append(models[i].predict(test_features))\n",
    "    \n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.sum(axis = 0)\n",
    "pred_labels = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy : {}\".format(accuracy_score(y_test, pred_labels)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = []\n",
    "for i in range(n_estimators):\n",
    "    pred.append(models[i].predict(p_features))\n",
    "    \n",
    "pred = np.array(pred)\n",
    "pred = pred.sum(axis = 0)\n",
    "pred_labels = pred.argmax(axis=1)\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-5].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = model.predict(x_train)\n",
    "test_features = model.predict(x_test)\n",
    "p_features = model.predict(x_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Activation , MaxPooling2D, Flatten\n",
    "\n",
    "model2 = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "input_shape = model2.layers[-4].get_input_shape_at(0) # get the input shape of desired layer\n",
    "layer_input = Input(shape = (9, 9, 512)) # a new input tensor to be able to feed the desired layer\n",
    "# https://stackoverflow.com/questions/52800025/keras-give-input-to-intermediate-layer-and-get-final-output\n",
    "\n",
    "x = layer_input\n",
    "for layer in model2.layers[-4::1]:\n",
    "    x = layer(x)\n",
    "    \n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100,activation='relu')(x)\n",
    "x = Dense(3,activation='softmax')(x)\n",
    "\n",
    "# create the model\n",
    "new_model = Model(layer_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 9, 9, 512)]       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       multiple                  2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       multiple                  2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       multiple                  2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 2, 2, 64)          294976    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,381,203\n",
      "Trainable params: 7,381,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1465 - accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 1.4847 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 1.1621 - accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 1.0717 - accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.0420 - accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.9776 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.9241 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 1.2476 - accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.9552 - accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.9685 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = new_model.fit(train_features,y_train, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = new_model.predict(test_features)    \n",
    "pred_labels = np.argmax(predictions, axis = 1)\n",
    "print(\"Accuracy : {}\".format(accuracy_score(y_test, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = new_model.predict(p_features)\n",
    "pred_labels = np.argmax(predictions, axis = 1)\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36a0d8ae7ea53d0c2bb98a357b7e4d666f857d54e9cfe25daaf029ef2b61f7f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
